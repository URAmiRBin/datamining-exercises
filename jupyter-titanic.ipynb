{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "[Kaggle page for this problem](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "*Amir Hossein Binesh*, Amir Kabir University of Tehran\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Read data, visualize and preprocess\n",
    "\n",
    "**Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read train data\n",
    "train_df = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "# Read test data and the answers\n",
    "test_features = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test_classes = pd.read_csv('gender_submission.csv', index_col='PassengerId')\n",
    "\n",
    "# concat test data and answers for integration\n",
    "test_df = pd.concat([test_features, test_classes], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features and data for train data\n",
    "print(\"Number of features : \", len(train_df.columns))\n",
    "print(\"Number of data : \", len(train_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features and data for test data\n",
    "print(\"Number of features : \", len(test_df.columns))\n",
    "print(\"Number of data : \", len(test_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Visualize the data**\n",
    "        \n",
    "With a little bit of common sense, and according to Titanic the movie, which I vaguely remember, we examine the features, to get a grasp of the data.\n",
    "This helps to choose features in next steps.\n",
    "\n",
    "\"Women and children first\", that gives a fairly easy clue, sex and age.\n",
    "The other thing is money, all the Pclass, Cabin, Fare and Ticket features point to this very specific matter, and also that lines up with the movie, so we have to have an eye on that.\n",
    "\n",
    "By the way, I couldn't find Jack in the data set, so maybe it's an alternative reality, who knows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fraction of survival and death for men and women\n",
    "dead_df = train_df[train_df['Survived'] == 0]\n",
    "alive_df = train_df[train_df['Survived'] == 1]\n",
    "plt.hist(train_df['Sex'].values, histtype='bar', bins=4, color = \"green\")\n",
    "plt.hist(dead_df['Sex'].values, histtype='bar', bins=4, color = \"red\")\n",
    "\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.legend(('Survived', 'Dead'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df['Age'].values, bins=5, color = \"green\", range = (0, 80))\n",
    "plt.hist(dead_df['Age'].values, bins=5, color = \"red\", range = (0, 80))\n",
    "\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Age')\n",
    "plt.legend(('Survived', 'Dead'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(alive_df['Fare']).plot(kind='density', color = \"green\")\n",
    "ax.set_xlim(-100, 500)\n",
    "pd.DataFrame(dead_df['Fare']).plot(ax=ax, kind='density', color = \"red\")\n",
    "\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Fare')\n",
    "plt.legend(('Survived', 'Dead'))\n",
    "plt.rcParams[\"figure.figsize\"] = [10,5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Data Preprocessing**\n",
    "\n",
    "As mentioned before, all the Pclass, Cabin, Fare and Ticket features, can sum up into one feature. The cabin NaN is probably for workers, we can make sure with a correlation method with fare, which is done below.\n",
    "\n",
    "So the Pclass and fare can represent the wealth.\n",
    "\n",
    "The other features are irrelevant to me. We can use Viktor Frankl teachings to add SibSp and Parch, but I don't think, that's gonna work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr(method ='kendall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation(Pclass, Fare) = -0.57, which is good, but not enough to ignore one over another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count null data\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null data for test data\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mean of age for NaN ages\n",
    "mean_age = round(train_df.mean(axis = 0, skipna = True)['Age'])\n",
    "train_df['Age'] = train_df['Age'].fillna(mean_age)\n",
    "mean_age = round(test_df.mean(axis = 0, skipna = True)['Age'])\n",
    "test_df['Age'] = test_df['Age'].fillna(mean_age)\n",
    "\n",
    "# Set Other NaNs\n",
    "train_df['Cabin'] = train_df['Cabin'].fillna(\"NoRoom\")\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(\"U\")\n",
    "test_df['Cabin'] = test_df['Cabin'].fillna(\"NoRoom\")\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna(\"U\")\n",
    "\n",
    "# Test data had one NaN for fare, use mean to replace it\n",
    "mean_fare = round(test_df.mean(axis = 0, skipna = True)['Fare'])\n",
    "test_df['Fare'] = test_df['Fare'].fillna(mean_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code, make a column into a numeric column\n",
    "# Since we decided to not use Cabin, I comment this out\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# enc = LabelEncoder()\n",
    "# enc.fit(train_df['Cabin'])\n",
    "# train_df['Cabin'] = enc.transform(train_df['Cabin'])\n",
    "\n",
    "train_df['Sex'].replace(['female', 'male'],[-1, 1], inplace=True)\n",
    "train_df['Embarked'].replace(['S', 'C', 'Q', 'U'], [0, 1, 2, 1], inplace=True)\n",
    "train_df['Survived'].replace([0, 1], [-1, 1], inplace = True)\n",
    "\n",
    "test_df['Sex'].replace(['female', 'male'],[0, 1], inplace=True)\n",
    "test_df['Embarked'].replace(['S', 'C', 'Q', 'U'], [0, 1, 2, 1], inplace=True)\n",
    "test_df['Survived'].replace([0, 1], [-1, 1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 : Training and testing the decision tree\n",
    "\n",
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# == SETTINGS ==\n",
    "MAX_DEPTH = 3\n",
    "CRITERION = \"entropy\"\n",
    "\n",
    "features = ['Sex', 'Age', 'Fare', 'Pclass']\n",
    "X = train_df[features]\n",
    "y = train_df['Survived']\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=0, max_depth=MAX_DEPTH, criterion=CRITERION)\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, clf.predict(train_df[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "file_name = \"Result-\" + str(MAX_DEPTH) + \"-\" + CRITERION\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(file_name)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                     feature_names=features,  \n",
    "                     class_names=['Survived', 'Dead'],  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df[features]\n",
    "y = test_df['Survived']\n",
    "predicc = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, predicc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
